"""
SCENE_GENERATOR.PY - Generador de prompts de escenas para video IA

Toma el texto de una historia ya guardada y genera prompts detallados
para generadores de video IA (Sora, Runway, Pika, Kling).

Integra el sistema de coherencia multi-agente:
  â†’ Agente 1: Director Creativo CGI  (genera cada escena)
  â†’ Agente 2: Editor Narrativo       (valida coherencia global)
  â†’ CorrecciÃ³n automÃ¡tica iterativa  (hasta MAX_FIX_ITERATIONS rondas)

Los archivos se guardan en:
  outputs/historias/revision/{TITULO}/prompts-scenas/
    â”œâ”€â”€ escena1.md          â† Prompt enriquecido para video IA
    â”œâ”€â”€ escenaN.md
    â”œâ”€â”€ RESUMEN_FINAL.md    â† PuntuaciÃ³n y problemas detectados
    â””â”€â”€ coherence_report_v{N}.json
"""

import json
import re
import time
from pathlib import Path
from typing import Optional

from openai import OpenAI

from config.config import OPENAI_MODEL, LOGS_DIR, IMAGE_MODEL
from .token_tracker import tracker

# â”€â”€ Constantes configurables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

COHERENCE_THRESHOLD = 85   # % mÃ­nimo para aprobar la coherencia
MAX_FIX_ITERATIONS  = 3    # Intentos mÃ¡ximos de correcciÃ³n automÃ¡tica
SCENE_MAX_TOKENS    = 1500
EDITOR_MAX_TOKENS   = 3000
SCENE_TEMPERATURE   = 0.7
EDITOR_TEMPERATURE  = 0.3


# â”€â”€ Prompts de los agentes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_SCENE_SYSTEM = """\
Eres un experto director creativo especializado en animaciÃ³n CGI estilo Pixar/Disney.
Tu trabajo es convertir pÃ¡rrafos de una historia infantil en prompts altamente detallados
para generadores de video IA (Sora, Runway ML, Pika, Kling).

REGLAS CRÃTICAS:
1. El prompt DEBE estar en INGLÃ‰S (los generadores de video responden mejor en inglÃ©s).
2. MantÃ©n ABSOLUTA coherencia visual con los personajes descritos (hex exactos, proporciones).
3. Cada escena incluye: ambiente, iluminaciÃ³n, cÃ¡mara, acciÃ³n, emociÃ³n y continuidad.
4. Incluye al final "CONTINUITY NOTES" con los elementos que DEBEN aparecer en la siguiente escena.
5. Estilo visual: 3D CGI animation, Pixar/Disney quality, soft studio lighting, vibrant colors, 8K render.
6. NO inventes caracterÃ­sticas fÃ­sicas nuevas. Ãšsalas exactamente como se describen.
7. DuraciÃ³n estimada de cada clip: 5-8 segundos.

ESTRUCTURA DEL PROMPT DE ESCENA (usa EXACTAMENTE estas secciones en este orden):

SCENE [N] â€” [TÃTULO CORTO DE LA ESCENA]

CHARACTERS DESCRIPTION:
[BLOQUE DE PERSONAJES â€” serÃ¡ inyectado automÃ¡ticamente, no lo reescribas]

ENVIRONMENT:
[Ambiente, hora del dÃ­a, clima, paleta de colores dominante]

CHARACTERS PRESENT:
[Personajes en escena con estado emocional actual]

ACTION & MOVEMENT:
[Secuencia de acciones exacta, movimiento de cÃ¡mara]

CAMERA:
[Tipo de plano, Ã¡ngulo, movimiento]

LIGHTING & MOOD:
[IluminaciÃ³n especÃ­fica, atmÃ³sfera emocional]

TECHNICAL:
[Estilo 3D, calidad render, duraciÃ³n estimada del clip]

CONTINUITY NOTES (for next scene):
[Elementos visuales, posiciÃ³n de personajes y objetos que deben continuar]
"""

_EDITOR_SYSTEM = """\
Eres un editor experto en narrativa visual, especializado en animaciÃ³n CGI y storyboarding.
Revisas secuencias de prompts de escenas para video animado y evalÃºas:

1. COHERENCIA VISUAL: Â¿Los personajes mantienen sus caracterÃ­sticas fÃ­sicas?
2. COHERENCIA NARRATIVA: Â¿La historia fluye lÃ³gicamente de escena en escena?
3. CONTINUIDAD DE AMBIENTE: Â¿Luz, objetos y clima son consistentes entre escenas?
4. CONTINUIDAD DE ACCIONES: Â¿Las acciones conectan fluidamente?
5. CLARIDAD PARA IA VIDEO: Â¿Cada prompt es suficientemente detallado?

RESPONDE ÃšNICAMENTE CON ESTE JSON EXACTO (sin markdown, sin bloques de cÃ³digo):
{
  "overall_score": <0-100>,
  "scene_scores": {"1": <0-100>, "2": <0-100>, ...},
  "issues": [
    {
      "scene": <nÃºmero>,
      "type": "visual|narrative|continuity|clarity",
      "description": "<descripciÃ³n>",
      "severity": "low|medium|high"
    }
  ],
  "corrections_needed": [
    {
      "scene": <nÃºmero>,
      "original_section": "<texto exacto a reemplazar>",
      "corrected_section": "<texto corregido>",
      "reason": "<razÃ³n>"
    }
  ],
  "summary": "<resumen ejecutivo en mÃ¡ximo 3 oraciones>",
  "passed": <true|false>
}
"""

_ILLUSTRATION_SYSTEM = """\
Eres un ilustrador experto especializado en libros de cuentos infantiles estilo Pixar/Disney CGI.
Tu trabajo es convertir pÃ¡rrafos de una historia en prompts detallados para generadores de imagen IA
(Midjourney, DALL-E 3, Adobe Firefly, Stable Diffusion XL).

DIFERENCIAS CLAVE con los prompts de video:
- Las ilustraciones son ESTÃTICAS: no hay movimiento, ni instrucciones de cÃ¡mara, ni duraciÃ³n.
- El ENVIRONMENT debe ser MUCHO mÃ¡s rico y detallado: texturas, luz ambiental, elementos decorativos,
  profundidad de campo visual, paleta cromÃ¡tica especÃ­fica con HEX, detalles del fondo que enriquecen
  la narrativa. Piensa como un director de arte de Pixar describiendo un cuadro.
- CHARACTERS PRESENT indica quiÃ©nes aparecen, su posiciÃ³n en el encuadre y expresiÃ³n emocional.
  No describas acciones dinÃ¡micas sino poses narrativas (posturas que cuentan la historia).
- CONTINUITY NOTES es mÃ¡s corta: solo posiciÃ³n de personajes y elementos de entorno a mantener.

REGLAS CRÃTICAS:
1. El prompt DEBE estar en INGLÃ‰S.
2. Respeta ABSOLUTAMENTE los colores HEX y proporciones de los personajes dados.
3. NO inventes rasgos fÃ­sicos nuevos en los personajes.
4. El ENVIRONMENT debe tener al menos 5-7 lÃ­neas de descripciÃ³n visual detallada.
   Incluye: ubicaciÃ³n, hora del dÃ­a, tipo de luz, sombras, colores dominantes con HEX aproximados,
   texturas del suelo/paredes/vegetaciÃ³n, elementos decorativos, profundidad (primer plano / fondo).
5. Estilo visual: 3D CGI illustration, Pixar/Disney quality, children's storybook, 8K render.
6. NO incluyas secciones de ACTION & MOVEMENT ni CAMERA.

ESTRUCTURA DEL PROMPT DE ILUSTRACIÃ“N (usa EXACTAMENTE estas secciones en este orden):

ILLUSTRATION [N] â€” [TÃTULO CORTO EVOCADOR]

CHARACTERS DESCRIPTION:
[BLOQUE DE PERSONAJES â€” serÃ¡ inyectado automÃ¡ticamente, no lo reescribas]

ENVIRONMENT:
[DescripciÃ³n visual MUY DETALLADA del entorno: mÃ­nimo 6 lÃ­neas.
Incluye: escenario completo, hora del dÃ­a, tipo de cielo/luz, fuentes de luz,
colores dominantes con HEX, texturas (suelo, vegetaciÃ³n, objetos),
elementos en primer plano / plano medio / fondo,
detalles decorativos que enriquecen la atmÃ³sfera del cuento.]

CHARACTERS PRESENT:
[Personajes en escena, su posiciÃ³n en el encuadre y expresiÃ³n/postura narrativa]

LIGHTING & MOOD:
[Tipo de luz, direcciÃ³n, temperatura de color, atmÃ³sfera emocional, estilo de sombreado]

COMPOSITION & STYLE:
[ComposiciÃ³n de la ilustraciÃ³n: regla de tercios, encuadre, profundidad.
Estilo artÃ­stico: 3D CGI storybook, Pixar quality, paleta de colores especÃ­fica.]

CONTINUITY NOTES (for next illustration):
[Elementos de posiciÃ³n y entorno que deben mantenerse en la siguiente ilustraciÃ³n]
"""

def _format_character(p: dict) -> str:
    """Formatea un personaje para el contexto del prompt del agente (formato compacto)."""
    parts = [f"\nâ€¢ {p.get('nombre', '?').upper()} ({p.get('species', '?')})"]
    skip = {"nombre", "species", "prompt-3D", "forbidden_changes"}
    for k, v in p.items():
        if k not in skip:
            parts.append(f"  - {k}: {v}")
    if "forbidden_changes" in p:
        parts.append(f"  âš ï¸ NO CAMBIAR: {p['forbidden_changes']}")
    return "\n".join(parts)


# Frases a eliminar del prompt-3D del secundario cuando se incrusta en la escena.
# Son instrucciones de fondo blanco / pose que solo aplican a generaciÃ³n de imagen suelta.
_FRASES_A_LIMPIAR_PROMPT3D = [
    "clean white studio background,",
    "clean white studio background.",
    "clean white studio background",
    "full body visible,",
    "full body visible.",
    "full body visible",
    "centered composition,",
    "centered composition.",
    "centered composition",
]


def _limpiar_prompt_3d(prompt: str) -> str:
    """
    Elimina del prompt-3D del secundario las instrucciones de fondo/pose
    que solo aplican cuando se genera la imagen suelta del personaje.
    Limpia tambiÃ©n comas/espacios residuales.
    """
    resultado = prompt
    for frase in _FRASES_A_LIMPIAR_PROMPT3D:
        resultado = resultado.replace(frase, "")
    # Limpiar mÃºltiples espacios y comas dobles residuales
    resultado = re.sub(r",\s*,", ",", resultado)
    resultado = re.sub(r"\s{2,}", " ", resultado)
    resultado = resultado.strip().strip(",").strip()
    return resultado


# â”€â”€ Helpers exclusivos de ilustraciones â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_secondary_block_for_md(characters_data: dict) -> str:
    """
    Construye el bloque del personaje secundario para el .md de ilustraciÃ³n.
    Solo incluye el secundario â€” Kira y Toby se omiten del .md porque sus
    prompts completos se inyectan directamente en el prompt de Google Imagen.
    """
    lines = []
    for p in characters_data.get("personajesSecundarios", []):
        nombre   = p.get("nombre", "personaje secundario")
        prompt3d = p.get("prompt-3D", "")
        if prompt3d:
            lines.append(f'"{nombre}": """{_limpiar_prompt_3d(prompt3d)}"""')
        else:
            skip   = {"nombre", "species", "prompt-3D", "forbidden_changes"}
            campos = [f"{k}: {v}" for k, v in p.items() if k not in skip]
            desc   = f"{p.get('species', 'character')}, {nombre}. " + ". ".join(campos)
            if "forbidden_changes" in p:
                desc += f". *** NEVER CHANGE: {p['forbidden_changes']}"
            lines.append(f'"{nombre}": """{desc}"""')

    if not lines:
        return ""
    return "PERSONAJE SECUNDARIO\n" + "\n".join(lines)


def _extract_illustration_section(text: str, section_name: str) -> str:
    """
    Extrae el contenido de una secciÃ³n nombrada del texto generado por OpenAI.
    Funciona con: ENVIRONMENT, CHARACTERS PRESENT, LIGHTING & MOOD,
                  COMPOSITION & STYLE, CONTINUITY NOTES.
    """
    pattern = re.compile(
        rf"{re.escape(section_name)}[^:]*:\s*\n(.*?)(?=\n[A-Z]{{2,}}[^:\n]*:|\Z)",
        re.DOTALL | re.IGNORECASE,
    )
    match = pattern.search(text)
    return match.group(1).strip() if match else ""


def _build_imagen_prompt_from_illustration(
    illustration_text: str,
    characters_data: dict,
) -> str:
    """
    Construye el prompt completo para Google Imagen combinando:
      - Prompts de Kira y Toby desde config/personajes.py  (referencia visual exacta)
      - Personaje secundario desde characters_data
      - Contexto de escena generado por OpenAI: ENVIRONMENT, CHARACTERS PRESENT,
        LIGHTING & MOOD, COMPOSITION & STYLE

    El .md guarda el contexto limpio; este prompt va directo a la API de imagen.
    """
    from config.personajes import PERSONAJES

    kira_prompt = _limpiar_prompt_3d(PERSONAJES.get("kira", ""))
    toby_prompt = _limpiar_prompt_3d(PERSONAJES.get("toby", ""))

    # Personaje(s) secundario(s)
    secondary_lines = []
    for p in characters_data.get("personajesSecundarios", []):
        nombre   = p.get("nombre", "personaje secundario")
        prompt3d = p.get("prompt-3D", "")
        if prompt3d:
            secondary_lines.append(f'"{nombre}": """{_limpiar_prompt_3d(prompt3d)}"""')

    # Secciones de contexto generadas por OpenAI
    env         = _extract_illustration_section(illustration_text, "ENVIRONMENT")
    chars       = _extract_illustration_section(illustration_text, "CHARACTERS PRESENT")
    lighting    = _extract_illustration_section(illustration_text, "LIGHTING & MOOD")
    composition = _extract_illustration_section(illustration_text, "COMPOSITION & STYLE")

    parts = [
        "CHARACTER REFERENCES (STRICT â€” use EXACT hex colors and proportions, never invent new traits):",
        "",
        f'kira: """{kira_prompt}"""',
        "",
        f'toby: """{toby_prompt}"""',
    ]
    if secondary_lines:
        parts += [""] + secondary_lines

    if env:
        parts += ["", "ENVIRONMENT:", env]
    if chars:
        parts += ["", "CHARACTERS PRESENT:", chars]
    if lighting:
        parts += ["", "LIGHTING & MOOD:", lighting]
    if composition:
        parts += ["", "COMPOSITION & STYLE:", composition]

    parts += [
        "",
        "ILLUSTRATION STYLE (MANDATORY):",
        "- 3D CGI children's storybook illustration, Pixar/Disney quality",
        "- Big expressive eyes, rounded cute proportions, soft fur textures",
        "- Richly detailed background with storytelling depth",
        "- Warm, harmonious color palette â€” no harsh or cold contrasts",
        "- 8K resolution, ultra-detailed, crisp clean edges",
        "- Strictly NO text, NO speech bubbles, NO watermarks, NO UI elements",
        "- Single complete illustration, NOT a comic strip or panel sequence",
    ]
    return "\n".join(parts)


def _build_runway_prompt_from_illustration(
    illustration_text: str,
    characters_data: dict,
) -> str:
    """
    VersiÃ³n compacta del prompt de ilustraciÃ³n para Runway (lÃ­mite: 1000 chars).
    Prioriza ENVIRONMENT y CHARACTERS PRESENT sobre las descripciones largas de personajes.
    Usa descripciones breves de Kira y Toby en lugar de los prompts completos de personajes.py.
    """
    # Descripciones breves de los protagonistas (caben en ~200 chars)
    kira_brief = "Kira: female Shiba Inu puppy, pale yellow fur #FFF9D4, brown eyes #5C4033, red heart bow on right ear, cute 3D Pixar style"
    toby_brief = "Toby: male Husky puppy, lavender fur #E8E3F0, heterochromatic eyes (left blue #6BB6D6, right brown #8B6F47), lightning bolt on left flank, cute 3D Pixar style"

    # Personaje secundario breve
    sec_brief = ""
    for p in characters_data.get("personajesSecundarios", []):
        nombre  = p.get("nombre", "")
        species = p.get("species", "")
        fur     = p.get("fur_color", "")
        acc     = p.get("accessory", "")
        sec_brief = f"{nombre}: {species}" + (f", {fur}" if fur else "") + (f", {acc}" if acc else "")
        break  # solo el primero

    env   = _extract_illustration_section(illustration_text, "ENVIRONMENT")
    chars = _extract_illustration_section(illustration_text, "CHARACTERS PRESENT")

    parts = [
        "3D CGI children's storybook illustration, Pixar/Disney quality.",
        f"CHARACTERS: {kira_brief}. {toby_brief}.",
    ]
    if sec_brief:
        parts.append(f"Secondary: {sec_brief}.")
    if env:
        # Tomar solo las 3 primeras lÃ­neas del environment
        env_short = " ".join(env.split("\n")[:3]).strip()
        parts.append(f"SCENE: {env_short}")
    if chars:
        chars_short = chars.split("\n")[0].strip()
        parts.append(f"CHARACTERS PRESENT: {chars_short}")
    parts.append("Warm magical atmosphere, big expressive eyes, no text, no watermarks.")

    prompt = " ".join(parts)
    return prompt[:1000]


def _save_illustration_slim(
    text: str,
    n: int,
    output_dir: Path,
    secondary_block: str = "",
) -> Path:
    """
    Guarda el prompt de ilustraciÃ³n en ilustracionN.md, versiÃ³n limpia:
      - Sin el bloque largo de Kira y Toby (eso va en el prompt de imagen)
      - Con una referencia compacta a personajes.py + personaje secundario
      - Mantiene ENVIRONMENT, CHARACTERS PRESENT, LIGHTING & MOOD,
        COMPOSITION & STYLE y CONTINUITY NOTES generados por OpenAI
    """
    # Eliminar la secciÃ³n CHARACTERS DESCRIPTION (Kira/Toby full block)
    text_clean = re.sub(
        r"\nCHARACTERS DESCRIPTION:.*?(?=\nENVIRONMENT:|\nCHARACTERS PRESENT:|\Z)",
        "",
        text,
        count=1,
        flags=re.DOTALL | re.IGNORECASE,
    ).strip()

    # Cabecera de referencia
    ref_lines = [
        "# PERSONAJES â€” REFERENCIA",
        "> **Kira** y **Toby**: descripciÃ³n visual completa en `config/personajes.py`",
    ]
    if secondary_block:
        ref_lines += ["", secondary_block]

    contenido = "\n".join(ref_lines) + "\n\n---\n\n" + text_clean
    path      = output_dir / f"ilustracion{n}.md"
    path.write_text(contenido, encoding="utf-8")
    return path


def build_characters_description(characters_data: dict) -> str:
    """
    Construye la descripciÃ³n compacta de personajes para el contexto
    del agente generador (user_msg). No se guarda en el .md.
    """
    lines = ["=== PERSONAJES Y SUS CARACTERÃSTICAS FÃSICAS FIJAS ===\n"]

    if "personajesPrincipales" in characters_data:
        lines.append("â”€â”€ PERSONAJES PRINCIPALES â”€â”€")
        for p in characters_data["personajesPrincipales"]:
            lines.append(_format_character(p))

    if "personajesSecundarios" in characters_data:
        lines.append("\nâ”€â”€ PERSONAJES SECUNDARIOS (incluir solo los presentes en la escena) â”€â”€")
        for p in characters_data["personajesSecundarios"]:
            lines.append(_format_character(p))

    if "objectosImportantes" in characters_data:
        lines.append("\nâ”€â”€ OBJETOS IMPORTANTES (mantener consistencia visual) â”€â”€")
        for obj in characters_data["objectosImportantes"]:
            parts = [f"\nâ€¢ {obj.get('nombre', '?').upper()}"]
            for k, v in obj.items():
                if k not in {"nombre", "forbidden_changes"}:
                    parts.append(f"  - {k}: {v}")
            if "forbidden_changes" in obj:
                parts.append(f"  âš ï¸ NO CAMBIAR: {obj['forbidden_changes']}")
            lines.append("\n".join(parts))

    return "\n".join(lines)


def build_characters_block_for_scene(characters_data: dict) -> str:
    """
    Construye el bloque CHARACTERS DESCRIPTION que se incrusta en cada
    archivo escenaN.md guardado.

    Formato:
      CHARACTERS DESCRIPTION:
      kira: \"\"\"<prompt completo de personajes.py>\"\"\"
      toby: \"\"\"<prompt completo de personajes.py>\"\"\"
      <nombre secundario>: \"\"\"<prompt-3D limpio del secundario>\"\"\"

    Kira y Toby: se usan los prompts completos de config/personajes.py
    (descripciÃ³n fÃ­sica exhaustiva con HEX, proporciones, negative prompts,
    consistencia visual obligatoria).

    Personaje secundario: se usa el campo prompt-3D del characters_data,
    limpiando las frases de fondo/pose que no aplican en el contexto de escena.

    Si characters_data no tiene los prompts de Kira/Toby (cuando se construye
    el dict mÃ­nimo en story_storage), usa los de personajes.py directamente.
    """
    from config.personajes import PERSONAJES

    bloques = ["CHARACTERS DESCRIPTION:"]

    # â”€â”€ Kira â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    kira_prompt = PERSONAJES.get("kira", "")
    # Limpiar frases de pose/fondo que no aplican en escena
    kira_prompt = _limpiar_prompt_3d(kira_prompt)
    bloques.append(f'kira: """{kira_prompt}"""')

    # â”€â”€ Toby â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    toby_prompt = PERSONAJES.get("toby", "")
    toby_prompt = _limpiar_prompt_3d(toby_prompt)
    bloques.append(f'toby: """{toby_prompt}"""')

    # â”€â”€ Personaje(s) secundario(s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for p in characters_data.get("personajesSecundarios", []):
        nombre   = p.get("nombre", "personaje secundario")
        prompt3d = p.get("prompt-3D", "")
        if prompt3d:
            prompt3d_limpio = _limpiar_prompt_3d(prompt3d)
            bloques.append(f'"{nombre}": """{prompt3d_limpio}"""')
        else:
            # Sin prompt-3D: construir descripciÃ³n compacta desde los campos disponibles
            campos = []
            skip   = {"nombre", "species", "prompt-3D", "forbidden_changes"}
            for k, v in p.items():
                if k not in skip:
                    campos.append(f"  - {k}: {v}")
            if "forbidden_changes" in p:
                campos.append(f"  *** NEVER CHANGE: {p['forbidden_changes']}")
            desc = f"{p.get('species', 'character')}, {p.get('nombre', '?')}.\n" + "\n".join(campos)
            bloques.append(f'"{nombre}": """{desc}"""')

    return "\n\n".join(bloques)


# â”€â”€ GeneraciÃ³n de escenas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_continuity_notes(scene_text: str) -> str:
    """Extrae la secciÃ³n CONTINUITY NOTES de un prompt generado."""
    match = re.search(
        r"CONTINUITY NOTES.*?:(.*?)(?=\n[A-Z]{2,}|\Z)",
        scene_text,
        re.DOTALL | re.IGNORECASE,
    )
    return match.group(1).strip() if match else ""


def _generate_single_scene(
    openai_client: OpenAI,
    paragraph: str,
    scene_number: int,
    total_scenes: int,
    characters_desc: str,
    previous_continuity: Optional[str],
    next_paragraph: Optional[str],
) -> tuple[str, dict]:
    """
    Genera el prompt de una escena individual.

    Returns:
        (prompt_text, usage_dict)
    """
    context_parts = []
    if previous_continuity:
        context_parts.append(f"CONTINUITY FROM PREVIOUS SCENE:\n{previous_continuity}")
    if next_paragraph:
        context_parts.append(
            f"NEXT PARAGRAPH (for visual continuity planning):\n{next_paragraph}"
        )

    user_msg = (
        f"{characters_desc}\n\n"
        f"{'â•'*50}\n"
        f"CURRENT PARAGRAPH (Scene {scene_number} of {total_scenes}):\n"
        f"{'â•'*50}\n"
        f"{paragraph}\n\n"
        f"{chr(10).join(context_parts)}\n\n"
        f"{'â•'*50}\n"
        f"Generate the complete scene prompt for Scene {scene_number}.\n"
        f"Make it detailed enough for an AI video generator.\n"
        f"End with CONTINUITY NOTES for the next scene.\n"
        f"{'â•'*50}"
    )

    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": _SCENE_SYSTEM},
            {"role": "user",   "content": user_msg},
        ],
        temperature=SCENE_TEMPERATURE,
        max_tokens=SCENE_MAX_TOKENS,
    )

    return (
        response.choices[0].message.content.strip(),
        {
            "prompt":     response.usage.prompt_tokens,
            "completion": response.usage.completion_tokens,
            "total":      response.usage.total_tokens,
        },
    )


# â”€â”€ ValidaciÃ³n y correcciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _validate_and_correct(
    openai_client: OpenAI,
    scenes: dict[int, str],
    characters_desc: str,
    story_paragraphs: list[str],
    threshold: int,
) -> tuple[dict, dict]:
    """
    Llama al agente editor para evaluar coherencia.

    Returns:
        (report_dict, usage_dict)
    """
    scenes_text = ("\n\n" + "=" * 60 + "\n\n").join(
        f"SCENE {n}:\n{text}" for n, text in sorted(scenes.items())
    )
    story_ref = "\n".join(
        f"Paragraph {i+1}: {p}" for i, p in enumerate(story_paragraphs)
    )

    user_msg = (
        f"{characters_desc}\n\n"
        f"{'â•'*50}\nORIGINAL STORY (reference):\n{'â•'*50}\n{story_ref}\n\n"
        f"{'â•'*50}\nGENERATED SCENE PROMPTS TO EVALUATE:\n{'â•'*50}\n{scenes_text}\n\n"
        f"{'â•'*50}\n"
        f"COHERENCE THRESHOLD: {threshold}%\n"
        f"Evaluate all scenes. Provide corrections if overall_score < {threshold}.\n"
        f"Respond ONLY with the JSON format. No markdown, no code blocks.\n"
        f"{'â•'*50}"
    )

    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": _EDITOR_SYSTEM},
            {"role": "user",   "content": user_msg},
        ],
        temperature=EDITOR_TEMPERATURE,
        max_tokens=EDITOR_MAX_TOKENS,
    )

    raw = response.choices[0].message.content.strip()
    raw = re.sub(r"```(?:json)?", "", raw).strip()

    usage = {
        "prompt":     response.usage.prompt_tokens,
        "completion": response.usage.completion_tokens,
        "total":      response.usage.total_tokens,
    }

    try:
        report = json.loads(raw)
    except json.JSONDecodeError:
        print("  âš ï¸  El editor devolviÃ³ JSON invÃ¡lido. ExtracciÃ³n parcial...")
        score_match = re.search(r'"overall_score"\s*:\s*(\d+)', raw)
        score = int(score_match.group(1)) if score_match else 50
        report = {
            "overall_score": score,
            "scene_scores": {},
            "issues": [],
            "corrections_needed": [],
            "summary": raw[:300],
            "passed": score >= threshold,
        }

    return report, usage


def _apply_corrections(
    scenes: dict[int, str],
    corrections: list[dict],
) -> tuple[dict[int, str], int]:
    """
    Aplica correcciones del editor. Devuelve (scenes_corregidas, n_aplicadas).
    """
    corrected = dict(scenes)
    applied = 0

    for fix in corrections:
        n     = fix.get("scene")
        orig  = fix.get("original_section", "")
        new   = fix.get("corrected_section", "")
        reason = fix.get("reason", "")

        if n and orig and new and n in corrected and orig in corrected[n]:
            corrected[n] = corrected[n].replace(orig, new, 1)
            applied += 1
            print(f"    âœï¸  Escena {n}: {reason[:80]}")

    return corrected, applied


# â”€â”€ Guardado de archivos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _inject_characters_block(scene_text: str, characters_block: str) -> str:
    """
    Inyecta el bloque CHARACTERS DESCRIPTION en el archivo de escena.

    El bloque canÃ³nico que se pasa ya empieza con "CHARACTERS DESCRIPTION:\n"
    (viene de build_characters_block_for_scene). La inyecciÃ³n lo escribe una
    sola vez, sin duplicar la etiqueta.

    Estrategia:
      1. Si el agente ya incluyÃ³ "CHARACTERS DESCRIPTION:" â†’ reemplaza todo ese
         bloque (etiqueta + contenido anterior) por el bloque canÃ³nico.
      2. Si no lo incluyÃ³ â†’ lo inserta antes de "ENVIRONMENT:".
      3. Fallback â†’ lo inserta tras la primera lÃ­nea de tÃ­tulo "SCENE N â€”".
    """
    # Caso 1: el agente incluyÃ³ la etiqueta â†’ reemplazar COMPLETO (etiqueta + contenido)
    # Capturamos desde la etiqueta hasta la siguiente secciÃ³n en mayÃºsculas o fin
    pattern_existing = re.compile(
        r"CHARACTERS DESCRIPTION:.*?(?=\n[A-Z][A-Z &]+:|\Z)",
        re.DOTALL | re.IGNORECASE,
    )
    if pattern_existing.search(scene_text):
        return pattern_existing.sub(characters_block, scene_text, count=1)

    # Caso 2: insertar entre tÃ­tulo y ENVIRONMENT:
    pattern_env = re.compile(r"(\nENVIRONMENT:)", re.IGNORECASE)
    if pattern_env.search(scene_text):
        return pattern_env.sub(f"\n\n{characters_block}\n\\1", scene_text, count=1)

    # Caso 3: fallback â€” insertar tras la primera lÃ­nea "SCENE N â€”..."
    lines = scene_text.split("\n")
    for i, line in enumerate(lines):
        if line.strip().upper().startswith("SCENE "):
            lines.insert(i + 1, f"\n{characters_block}\n")
            return "\n".join(lines)

    # Ãšltimo recurso
    return f"{characters_block}\n\n{scene_text}"


def _save_scene(
    text: str,
    n: int,
    output_dir: Path,
    characters_block: str = "",
) -> Path:
    """
    Guarda el prompt de una escena en escenaN.md.

    Si se pasa characters_block, lo inyecta en el archivo de forma determinista
    (siempre aparece, independientemente de lo que haya generado el agente).
    """
    contenido = _inject_characters_block(text, characters_block) if characters_block else text
    path = output_dir / f"escena{n}.md"
    path.write_text(contenido, encoding="utf-8")
    return path


def _save_report(report: dict, iteration: int, output_dir: Path) -> Path:
    path = output_dir / f"coherence_report_v{iteration}.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    return path


def _save_summary(
    scenes: dict[int, str],
    report: dict,
    output_dir: Path,
    token_summary: dict,
) -> Path:
    """Genera RESUMEN_FINAL.md con puntuaciones, problemas y resumen de tokens."""
    score  = report.get("overall_score", 0)
    passed = report.get("passed", False)

    lines = [
        "# ğŸ¬ RESUMEN FINAL â€” GENERADOR DE ESCENAS",
        "",
        f"## PuntuaciÃ³n de Coherencia: **{score}%** "
        f"{'âœ… APROBADO' if passed else 'âŒ REQUIERE REVISIÃ“N MANUAL'}",
        "",
        "### Resumen del Editor:",
        report.get("summary", "N/A"),
        "",
        "---",
        "",
        "## Puntuaciones por Escena:",
        "",
    ]

    scene_scores = report.get("scene_scores", {})
    for n in sorted(scenes.keys()):
        sc    = scene_scores.get(str(n), scene_scores.get(n, "N/A"))
        emoji = "âœ…" if isinstance(sc, int) and sc >= 80 else "âš ï¸"
        lines.append(f"- **Escena {n}**: {sc}% {emoji}")

    issues = report.get("issues", [])
    if issues:
        lines += ["", "---", "", "## Problemas Detectados:", ""]
        for issue in issues:
            sev = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                issue.get("severity", "low"), "âšª"
            )
            lines.append(
                f"- {sev} **Escena {issue.get('scene')}** "
                f"[{issue.get('type', '?')}]: {issue.get('description', '')}"
            )

    # â”€â”€ Resumen de tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ts = token_summary
    lines += [
        "",
        "---",
        "",
        "## ğŸ“Š Consumo de Tokens (este proceso)",
        "",
        f"| Concepto | Tokens | Costo estimado |",
        f"|----------|--------|----------------|",
        f"| GeneraciÃ³n de escenas | {ts.get('scene_tokens', 0):,} | ${ts.get('scene_cost', 0):.4f} USD |",
        f"| ValidaciÃ³n / Editor   | {ts.get('editor_tokens', 0):,} | ${ts.get('editor_cost', 0):.4f} USD |",
        f"| **TOTAL**             | **{ts.get('total_tokens', 0):,}** | **${ts.get('total_cost', 0):.4f} USD** |",
        "",
        "> Los costos son estimaciones basadas en precios pÃºblicos de OpenAI.",
        "> Consulta `logs/token_usage.json` para el historial acumulado.",
    ]

    lines += [
        "",
        "---",
        "",
        "## Archivos Generados:",
        "",
    ]
    for n in sorted(scenes.keys()):
        lines.append(f"- `escena{n}.md` â€” Prompt enriquecido para generador de video IA")

    lines += [
        "",
        "---",
        "_Generado automÃ¡ticamente por scene_generator.py (Proyecto Estelar)_",
    ]

    path = output_dir / "RESUMEN_FINAL.md"
    path.write_text("\n".join(lines), encoding="utf-8")
    return path


# â”€â”€ Pipeline principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generar_escenas_desde_historia(
    story_text: str,
    characters_data: dict,
    output_dir: Path,
    threshold: int = COHERENCE_THRESHOLD,
    only_validate: bool = False,
    historia_titulo: str = "",
) -> dict:
    """
    Pipeline completo: texto de historia â†’ prompts de escenas validados.

    Args:
        story_text:       Texto completo de la historia (extraÃ­do del .txt)
        characters_data:  Dict del characters.json (personajesPrincipales, etc.)
        output_dir:       Carpeta donde guardar los escenaN.md
                          (normalmente: outputs/historias/revision/TITULO/prompts-scenas/)
        threshold:        Porcentaje mÃ­nimo de coherencia (default: 85)
        only_validate:    Si True, solo valida escenas ya existentes
        historia_titulo:  TÃ­tulo para mostrar en los mensajes de consola

    Returns:
        dict con:
          - scenes_count     (int)
          - coherence_score  (int)
          - passed           (bool)
          - output_dir       (str)
          - tokens           (dict con desglose)
          - costo_estimado_usd (float)
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    tracker.set_log_path(LOGS_DIR)

    openai_client = OpenAI()

    label = f" â€” {historia_titulo}" if historia_titulo else ""
    print(f"\n{'â•'*62}")
    print(f"   ğŸ¬  GENERADOR DE ESCENAS{label}")
    print(f"{'â•'*62}\n")

    # 1. Preparar datos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    characters_desc  = build_characters_description(characters_data)
    characters_block = build_characters_block_for_scene(characters_data)

    # Extraer pÃ¡rrafos de la historia
    # El .txt tiene cabecera con ===, extraemos solo el bloque de texto narrativo
    story_clean = _extract_story_text(story_text)
    paragraphs  = [p.strip() for p in re.split(r"\n\s*\n", story_clean.strip()) if p.strip()]
    total       = len(paragraphs)
    print(f"ğŸ“– PÃ¡rrafos detectados: {total}\n")

    token_summary = {
        "scene_tokens": 0, "scene_cost": 0.0,
        "editor_tokens": 0, "editor_cost": 0.0,
        "total_tokens": 0, "total_cost": 0.0,
    }

    # 2. Generar o cargar escenas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    scenes: dict[int, str] = {}

    if only_validate:
        print("ğŸ” Modo solo-validaciÃ³n: cargando escenas existentes...")
        for i in range(1, total + 1):
            path = output_dir / f"escena{i}.md"
            if path.exists():
                texto_existente = path.read_text(encoding="utf-8")
                # Re-inyectar el bloque de personajes aunque ya exista la escena
                # (actualiza con los personajes actuales del characters.json)
                scenes[i] = texto_existente
                _save_scene(texto_existente, i, output_dir, characters_block)
                print(f"  âœ… escena{i}.md cargada (bloque de personajes actualizado)")
            else:
                print(f"  âŒ escena{i}.md no encontrada â€” saltando")
    else:
        print(f"ğŸ–Šï¸  Generando {total} prompts de escenas...\n")
        continuity = None

        for i, paragraph in enumerate(paragraphs, start=1):
            print(f"  ğŸ¨ Generando escena {i}/{total}...")

            next_para = paragraphs[i] if i < total else None

            prompt_text, usage = _generate_single_scene(
                openai_client=openai_client,
                paragraph=paragraph,
                scene_number=i,
                total_scenes=total,
                characters_desc=characters_desc,
                previous_continuity=continuity,
                next_paragraph=next_para,
            )

            scenes[i]  = prompt_text
            _save_scene(prompt_text, i, output_dir, characters_block)
            continuity = _extract_continuity_notes(prompt_text)

            # Registrar tokens
            entry = tracker.register_openai(
                operation=f"escena_{i}_de_{total}",
                model=OPENAI_MODEL,
                prompt_tokens=usage["prompt"],
                completion_tokens=usage["completion"],
                total_tokens=usage["total"],
                metadata={"historia": historia_titulo, "escena": i},
            )
            token_summary["scene_tokens"] += usage["total"]
            token_summary["scene_cost"]   += entry["estimated_cost_usd"]
            tracker.print_entry(entry)

            print(f"    âœ… escena{i}.md guardada")
            time.sleep(0.3)

    if not scenes:
        print("âŒ No hay escenas para procesar.")
        return {"scenes_count": 0, "coherence_score": 0, "passed": False}

    # 3. Bucle de validaciÃ³n + correcciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n{'â•'*62}")
    print(f"   ğŸ”¬  AGENTE EDITOR â€” VALIDANDO (umbral: {threshold}%)")
    print(f"{'â•'*62}\n")

    final_report = {}
    for iteration in range(1, MAX_FIX_ITERATIONS + 1):
        print(f"  IteraciÃ³n {iteration}/{MAX_FIX_ITERATIONS}...")

        report, usage = _validate_and_correct(
            openai_client, scenes, characters_desc, paragraphs, threshold
        )
        final_report = report

        # Registrar tokens del editor
        entry = tracker.register_openai(
            operation=f"editor_iteracion_{iteration}",
            model=OPENAI_MODEL,
            prompt_tokens=usage["prompt"],
            completion_tokens=usage["completion"],
            total_tokens=usage["total"],
            metadata={"historia": historia_titulo, "iteracion": iteration},
        )
        token_summary["editor_tokens"] += usage["total"]
        token_summary["editor_cost"]   += entry["estimated_cost_usd"]
        tracker.print_entry(entry)

        score  = report.get("overall_score", 0)
        passed = report.get("passed", False)
        issues = report.get("issues", [])
        fixes  = report.get("corrections_needed", [])

        _save_report(report, iteration, output_dir)
        print(f"  ğŸ“Š Score: {score}% | Problemas: {len(issues)} | Correcciones: {len(fixes)}")

        if passed:
            print(f"\n  âœ… COHERENCIA APROBADA ({score}% â‰¥ {threshold}%)")
            break

        if fixes and iteration < MAX_FIX_ITERATIONS:
            print(f"\n  âš™ï¸  Aplicando {len(fixes)} correcciones...")
            scenes, applied = _apply_corrections(scenes, fixes)
            print(f"  â†’ {applied}/{len(fixes)} aplicadas")
            for n, text in scenes.items():
                _save_scene(text, n, output_dir, characters_block)
        elif iteration == MAX_FIX_ITERATIONS:
            print(
                f"\n  âš ï¸  MÃ¡ximo de iteraciones alcanzado. "
                f"Score final: {score}%. RevisiÃ³n manual recomendada."
            )

    # 4. Totales y resumen final â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    token_summary["total_tokens"] = token_summary["scene_tokens"] + token_summary["editor_tokens"]
    token_summary["total_cost"]   = round(token_summary["scene_cost"] + token_summary["editor_cost"], 6)

    summary_path = _save_summary(scenes, final_report, output_dir, token_summary)

    final_score = final_report.get("overall_score", 0)
    final_passed = final_report.get("passed", False)

    print(f"\n{'â•'*62}")
    print(f"   ğŸ  PROCESO COMPLETADO")
    print(f"{'â•'*62}")
    print(f"\n  ğŸ“ Salida: {output_dir.resolve()}")
    for n in sorted(scenes.keys()):
        print(f"     â€¢ escena{n}.md")
    print(f"     â€¢ RESUMEN_FINAL.md")
    print(f"     â€¢ coherence_report_v*.json")
    print(f"\n  ğŸ“Š Tokens usados (este proceso): {token_summary['total_tokens']:,}")
    print(f"  ğŸ’° Costo estimado:               ${token_summary['total_cost']:.4f} USD\n")

    return {
        "scenes_count":       len(scenes),
        "coherence_score":    final_score,
        "passed":             final_passed,
        "output_dir":         str(output_dir),
        "tokens":             token_summary,
        "costo_estimado_usd": token_summary["total_cost"],
    }


# â”€â”€ Helper: extraer solo el texto narrativo del .txt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_story_text(full_txt: str) -> str:
    """
    Extrae ÃšNICAMENTE los pÃ¡rrafos narrativos de la historia.

    El .txt generado por story_storage tiene este formato:
        ===...===
        HISTORIA GENERADA â€” KIRA Y TOBY
        ===...===
        Fecha y hora: ...
        Modelo: ...
        ===...===

        **TÃTULO:** ...

        **HISTORIA:**
        <pÃ¡rrafo 1>

        <pÃ¡rrafo 2>
        ...

        **MORALEJA:**
        ...

        **ESCENAS:**
        ...

        ===...===
        ELEMENTOS UTILIZADOS:
        ...

    Solo queremos los pÃ¡rrafos entre **HISTORIA:** y la siguiente secciÃ³n
    (**MORALEJA:**, **ESCENAS:** o la lÃ­nea de ===).

    Funciona tambiÃ©n con .md o .txt planos (sin cabecera).
    """

    # â”€â”€ Intento 1: extraer bloque HISTORIA â†’ siguiente secciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Soporta dos formatos que GPT puede generar:
    #   **HISTORIA:**   (negrita, formato pedido en el prompt)
    #   ### HISTORIA:   (heading markdown, formato alternativo)
    historia_match = re.search(
        r"(?:\*\*HISTORIA:\*\*|#{1,3}\s*HISTORIA:)\s*\n"
        r"(.*?)"
        r"(?=\n(?:\*\*(?:MORALEJA|ESCENAS):\*\*|#{1,3}\s*(?:MORALEJA|ESCENAS):)|={10,}|\Z)",
        full_txt,
        re.DOTALL,
    )
    if historia_match:
        texto = historia_match.group(1).strip()
        if texto:
            return texto

    # â”€â”€ Intento 2: extraer el bloque del .txt con cabecera === â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Toma todo lo que estÃ¡ entre la cabecera y ELEMENTOS UTILIZADOS
    bloque_match = re.compile(
        r"={10,}\n"
        r"(?:Fecha.*?\n.*?\n)?"
        r"={10,}\n\n"
        r"(.*?)"
        r"\n\n={10,}",
        re.DOTALL,
    ).search(full_txt)

    if bloque_match:
        bloque = bloque_match.group(1).strip()
        # Del bloque, quedarnos solo con los pÃ¡rrafos que no son headers markdown
        # Filtramos lÃ­neas que empiezan con ** (secciones como **TÃTULO:**, etc.)
        paragraphs = []
        current = []
        for line in bloque.split("\n"):
            stripped = line.strip()
            # Detectar inicio de secciÃ³n markdown tipo **SECCIÃ“N:**
            if re.match(r"^\*\*[A-ZÃÃ‰ÃÃ“ÃšÃ‘\s]+:\*\*", stripped):
                if current:
                    block_text = "\n".join(current).strip()
                    if block_text:
                        paragraphs.append(block_text)
                    current = []
                # Si es **HISTORIA:** empezamos a capturar
                if "HISTORIA" in stripped.upper():
                    current = []
                else:
                    current = None   # type: ignore  # parar captura
            elif current is not None:
                current.append(line)

        if current:
            block_text = "\n".join(current).strip()
            if block_text:
                paragraphs.append(block_text)

        if paragraphs:
            return "\n\n".join(paragraphs)

    # â”€â”€ Fallback: texto plano (sin formato de proyecto) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ãštil para .md puros o historia.md de prueba
    return full_txt.strip()


# â”€â”€ Generador de ilustraciones de cuento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _generate_single_illustration(
    openai_client: OpenAI,
    paragraph: str,
    scene_number: int,
    total_scenes: int,
    characters_desc: str,
    previous_continuity: Optional[str],
    next_paragraph: Optional[str],
) -> tuple[str, dict]:
    """
    Genera el prompt de UNA ilustraciÃ³n de cuento infantil.
    Usa _ILLUSTRATION_SYSTEM en lugar de _SCENE_SYSTEM.

    Returns:
        (prompt_text, usage_dict)
    """
    context_parts = []
    if previous_continuity:
        context_parts.append(f"CONTINUITY FROM PREVIOUS ILLUSTRATION:\n{previous_continuity}")
    if next_paragraph:
        context_parts.append(
            f"NEXT PARAGRAPH (for visual continuity planning):\n{next_paragraph}"
        )

    user_msg = (
        f"{characters_desc}\n\n"
        f"{'â•'*50}\n"
        f"STORY PARAGRAPH (Illustration {scene_number} of {total_scenes}):\n"
        f"{'â•'*50}\n"
        f"{paragraph}\n\n"
        f"{chr(10).join(context_parts)}\n\n"
        f"{'â•'*50}\n"
        f"Generate the complete illustration prompt for Illustration {scene_number}.\n"
        f"The ENVIRONMENT section must be VERY detailed (at least 6 lines):\n"
        f"  - Exact location, time of day, type of sky\n"
        f"  - Light sources, shadows, color temperature\n"
        f"  - Dominant color palette with HEX codes where possible\n"
        f"  - Surface textures (ground, walls, vegetation, water, etc.)\n"
        f"  - Foreground / midground / background elements\n"
        f"  - Decorative details that reinforce the story atmosphere\n"
        f"Do NOT include ACTION & MOVEMENT or CAMERA sections.\n"
        f"End with short CONTINUITY NOTES for the next illustration.\n"
        f"{'â•'*50}"
    )

    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": _ILLUSTRATION_SYSTEM},
            {"role": "user",   "content": user_msg},
        ],
        temperature=SCENE_TEMPERATURE,
        max_tokens=SCENE_MAX_TOKENS + 500,   # mÃ¡s tokens para el ENVIRONMENT expandido
    )

    return (
        response.choices[0].message.content.strip(),
        {
            "prompt":     response.usage.prompt_tokens,
            "completion": response.usage.completion_tokens,
            "total":      response.usage.total_tokens,
        },
    )


def _save_illustration(
    text: str,
    n: int,
    output_dir: Path,
    characters_block: str = "",
) -> Path:
    """Guarda el prompt de ilustraciÃ³n en ilustracionN.md con el bloque de personajes inyectado."""
    contenido = _inject_characters_block(text, characters_block) if characters_block else text
    path = output_dir / f"ilustracion{n}.md"
    path.write_text(contenido, encoding="utf-8")
    return path


def generar_ilustraciones_desde_historia(
    story_text: str,
    characters_data: dict,
    output_dir: Path,
    historia_titulo: str = "",
    model: str = "gemini",
) -> dict:
    """
    Pipeline completo: texto de historia â†’ prompts de ilustraciÃ³n de cuento.

    Genera un archivo ilustracionN.md por cada pÃ¡rrafo de la historia.
    Los prompts estÃ¡n optimizados para generadores de imagen estÃ¡tica
    (Midjourney, DALL-E 3, Adobe Firefly, Stable Diffusion XL).

    Diferencias respecto a generar_escenas_desde_historia:
      - Usa _ILLUSTRATION_SYSTEM (sin ACTION, sin CAMERA, ENVIRONMENT expandido)
      - Guarda en ilustracionN.md (no en escenaN.md)
      - No ejecuta el agente editor de coherencia (no aplica para imÃ¡genes estÃ¡ticas)
      - El ENVIRONMENT se genera con mucho mÃ¡s detalle visual

    Args:
        story_text:       Texto completo de la historia (el .txt con cabecera)
        characters_data:  Dict del characters.json
        output_dir:       Carpeta de salida (normalmente prompts-scenas/)
        historia_titulo:  TÃ­tulo para los mensajes de consola

    Returns:
        dict con scenes_count, output_dir, tokens, costo_estimado_usd
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    tracker.set_log_path(LOGS_DIR)

    openai_client = OpenAI()

    label = f" â€” {historia_titulo}" if historia_titulo else ""
    print(f"\n{'â•'*62}")
    print(f"   ğŸ–¼ï¸  GENERADOR DE ILUSTRACIONES{label}")
    print(f"{'â•'*62}\n")

    # characters_desc â†’ contexto compacto para que OpenAI genere buenos ENVIRONMENT etc.
    # secondary_block â†’ bloque slim solo con el secundario, para el encabezado del .md
    characters_desc  = build_characters_description(characters_data)
    secondary_block  = _build_secondary_block_for_md(characters_data)

    story_clean = _extract_story_text(story_text)
    paragraphs  = [p.strip() for p in re.split(r"\n\s*\n", story_clean.strip()) if p.strip()]
    total       = len(paragraphs)
    print(f"ğŸ“– PÃ¡rrafos detectados: {total}\n")

    token_summary = {
        "illus_tokens": 0, "illus_cost": 0.0,
        "img_count":    0, "img_cost":   0.0,
        "total_tokens": 0, "total_cost": 0.0,
    }

    illustrations: dict[int, str] = {}
    continuity = None

    print(f"ğŸ–Šï¸  Generando {total} ilustraciones (prompt .md + imagen PNG)...\n")

    # Import lazy para no requerir google-genai si solo se generan .md
    try:
        from .image_generator import _llamar_imagen_api
        _imagen_disponible = True
    except Exception:
        _imagen_disponible = False
        print("  âš ï¸  image_generator no disponible â€” solo se generarÃ¡n los .md\n")

    for i, paragraph in enumerate(paragraphs, start=1):
        print(f"  ğŸ¨ Generando ilustraciÃ³n {i}/{total}...")

        next_para = paragraphs[i] if i < total else None

        prompt_text, usage = _generate_single_illustration(
            openai_client=openai_client,
            paragraph=paragraph,
            scene_number=i,
            total_scenes=total,
            characters_desc=characters_desc,
            previous_continuity=continuity,
            next_paragraph=next_para,
        )

        illustrations[i] = prompt_text

        # â”€â”€ 1. Guardar .md limpio (sin Kira/Toby extendidos) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _save_illustration_slim(prompt_text, i, output_dir, secondary_block)
        continuity = _extract_continuity_notes(prompt_text)

        entry = tracker.register_openai(
            operation=f"ilustracion_{i}_de_{total}",
            model=OPENAI_MODEL,
            prompt_tokens=usage["prompt"],
            completion_tokens=usage["completion"],
            total_tokens=usage["total"],
            metadata={"historia": historia_titulo, "ilustracion": i},
        )
        token_summary["illus_tokens"] += usage["total"]
        token_summary["illus_cost"]   += entry["estimated_cost_usd"]
        tracker.print_entry(entry)
        print(f"    âœ… ilustracion{i}.md guardada")

        # â”€â”€ 2. Generar PNG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if _imagen_disponible:
            if model == "runway":
                imagen_prompt = _build_runway_prompt_from_illustration(
                    prompt_text, characters_data
                )
            else:
                imagen_prompt = _build_imagen_prompt_from_illustration(
                    prompt_text, characters_data
                )
            imagen_bytes = _llamar_imagen_api(imagen_prompt, model=model)
            if imagen_bytes:
                ruta_png = output_dir / f"ilustracion{i}.png"
                ruta_png.write_bytes(imagen_bytes)
                img_entry = tracker.register_image(
                    operation=f"ilustracion_png_{i}_de_{total}",
                    model=IMAGE_MODEL,
                    images_count=1,
                    metadata={"historia": historia_titulo, "ilustracion": i, "backend": model},
                )
                token_summary["img_count"] += 1
                token_summary["img_cost"]  += img_entry.get("estimated_cost_usd", 0.0)
                tracker.print_entry(img_entry)
                print(f"    ğŸ–¼ï¸  ilustracion{i}.png generada")
            else:
                print(f"    âš ï¸  PNG no generado para ilustraciÃ³n {i} (fallo de API)")

        time.sleep(0.3)

    token_summary["total_tokens"] = token_summary["illus_tokens"]
    token_summary["total_cost"]   = round(
        token_summary["illus_cost"] + token_summary["img_cost"], 6
    )

    imgs_ok = token_summary["img_count"]
    print(f"\n{'â•'*62}")
    print(f"   ğŸ  ILUSTRACIONES COMPLETADAS")
    print(f"{'â•'*62}")
    print(f"\n  ğŸ“ Salida: {output_dir.resolve()}")
    for n in sorted(illustrations.keys()):
        png_ok = (output_dir / f"ilustracion{n}.png").exists()
        print(f"     â€¢ ilustracion{n}.md {'+ ilustracion' + str(n) + '.png' if png_ok else '(solo .md)'}")
    print(f"\n  ğŸ“Š Tokens texto:   {token_summary['illus_tokens']:,}")
    print(f"  ğŸ–¼ï¸  ImÃ¡genes PNG:   {imgs_ok}/{total}")
    print(f"  ğŸ’° Costo estimado: ${token_summary['total_cost']:.4f} USD\n")

    return {
        "scenes_count":       len(illustrations),
        "output_dir":         str(output_dir),
        "tokens":             token_summary,
        "costo_estimado_usd": token_summary["total_cost"],
    }


# â”€â”€ Punto de entrada standalone (para uso directo) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_standalone(
    story_path: str,
    characters_path: str,
    output_dir: str = ".",
    threshold: int = COHERENCE_THRESHOLD,
    only_validate: bool = False,
):
    """
    EjecuciÃ³n directa sin pasar por main.py del proyecto Estelar.
    Ãštil para procesar historias guardadas manualmente.

    Args:
        story_path:      Ruta al .txt o .md con la historia
        characters_path: Ruta al characters.json
        output_dir:      Directorio donde guardar los escenaN.md
        threshold:       Umbral de coherencia
        only_validate:   Solo validar escenas existentes
    """
    story_text = Path(story_path).read_text(encoding="utf-8")

    with open(characters_path, "r", encoding="utf-8") as f:
        characters_data = json.load(f)

    titulo = Path(story_path).stem

    generar_escenas_desde_historia(
        story_text=story_text,
        characters_data=characters_data,
        output_dir=Path(output_dir),
        threshold=threshold,
        only_validate=only_validate,
        historia_titulo=titulo,
    )