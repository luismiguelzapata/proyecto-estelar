"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           GENERADOR DE ESCENAS PARA HISTORIAS ANIMADAS                       â•‘
â•‘           Con IA OpenAI + Sistema de Coherencia Multi-Agente                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USO:
    python scene_generator.py --story historia.md --characters characters.json
    python scene_generator.py --story historia.md --characters characters.json --only-validate
    python scene_generator.py --story historia.md --characters characters.json --threshold 90

REQUISITOS:
    pip install openai python-dotenv

ARCHIVOS NECESARIOS:
    - historia.md         â†’ La historia a procesar
    - characters.json     â†’ DescripciÃ³n fÃ­sica de los personajes
    - .env                â†’ OPENAI_API_KEY=sk-...
"""

import os
import json
import re
import time
import argparse
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€â”€ ConfiguraciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MODEL_SCENE    = "gpt-4o"          # Modelo para generar escenas individuales
MODEL_EDITOR   = "gpt-4o"          # Modelo para el agente editor/validador
COHERENCE_THRESHOLD = 85           # % mÃ­nimo para dar la historia como buena
MAX_FIX_ITERATIONS  = 3            # MÃ¡ximo de intentos de correcciÃ³n automÃ¡tica


# â”€â”€â”€ Lectura de personajes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_characters(characters_path: str) -> str:
    """
    Lee el JSON de personajes y devuelve una descripciÃ³n compacta
    lista para ser incluida en los prompts del generador de escenas.
    """
    with open(characters_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    lines = ["=== PERSONAJES Y SUS CARACTERÃSTICAS FÃSICAS FIJAS ===\n"]

    # Personajes principales (si el JSON los tiene separados)
    if "personajesPrincipales" in data:
        lines.append("â”€â”€ PERSONAJES PRINCIPALES â”€â”€")
        for p in data["personajesPrincipales"]:
            lines.append(_format_character(p))

    # Personajes secundarios
    if "personajesSecundarios" in data:
        lines.append("\nâ”€â”€ PERSONAJES SECUNDARIOS (usar solo los presentes en la escena) â”€â”€")
        for p in data["personajesSecundarios"]:
            lines.append(_format_character(p))

    return "\n".join(lines)


def _format_character(p: dict) -> str:
    """Formatea un personaje para el contexto del prompt."""
    parts = [f"\nâ€¢ {p.get('nombre','?').upper()} ({p.get('species','?')})"]
    skip = {"nombre", "species", "prompt-3D", "forbidden_changes"}
    for k, v in p.items():
        if k not in skip:
            parts.append(f"  - {k}: {v}")
    if "forbidden_changes" in p:
        parts.append(f"  âš ï¸ NO CAMBIAR: {p['forbidden_changes']}")
    return "\n".join(parts)


# â”€â”€â”€ Lectura de la historia â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_story(story_path: str) -> list[str]:
    """
    Lee historia.md y devuelve una lista de pÃ¡rrafos no vacÃ­os.
    """
    text = Path(story_path).read_text(encoding="utf-8")
    # Dividir por lÃ­neas en blanco
    raw_paragraphs = re.split(r"\n\s*\n", text.strip())
    paragraphs = [p.strip() for p in raw_paragraphs if p.strip()]
    print(f"ğŸ“– Historia cargada: {len(paragraphs)} pÃ¡rrafos encontrados.")
    return paragraphs


# â”€â”€â”€ Generador de escenas individuales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENE_SYSTEM_PROMPT = """Eres un experto director creativo especializado en animaciÃ³n CGI estilo Pixar/Disney.
Tu trabajo es convertir pÃ¡rrafos de una historia infantil en prompts altamente detallados 
para generadores de video IA (como Sora, Runway ML, Pika, Kling).

REGLAS CRÃTICAS:
1. El prompt debe ser en INGLÃ‰S (los generadores de video IA responden mejor en inglÃ©s).
2. MantÃ©n ABSOLUTA coherencia visual con los personajes descritos (colores hex exactos, proporciones, accesorios).
3. Cada escena debe incluir: ambiente, iluminaciÃ³n, cÃ¡mara, acciÃ³n, emociÃ³n y continuidad.
4. Incluye al final una secciÃ³n "CONTINUITY NOTES" con elementos visuales que DEBEN aparecer en la siguiente escena.
5. El estilo visual es: 3D CGI animation, Pixar/Disney quality, soft studio lighting, vibrant colors, 8K render.
6. NO inventes caracterÃ­sticas fÃ­sicas nuevas para los personajes. Ãšsalas exactamente como se describe.
7. La duraciÃ³n estimada de cada clip debe ser de 5-8 segundos de video.

ESTRUCTURA DEL PROMPT DE ESCENA:
```
SCENE [N] â€” [TÃTULO CORTO DE LA ESCENA]

ENVIRONMENT:
[DescripciÃ³n del ambiente, hora del dÃ­a, clima, paleta de colores]

CHARACTERS PRESENT:
[Lista de personajes en escena con su estado emocional]

ACTION & MOVEMENT:
[QuÃ© ocurre exactamente, movimientos de cÃ¡mara, secuencia de acciÃ³n]

CAMERA:
[Tipo de plano, Ã¡ngulo, movimiento de cÃ¡mara]

LIGHTING & MOOD:
[IluminaciÃ³n especÃ­fica, atmÃ³sfera emocional]

TECHNICAL:
[Estilo 3D, calidad render, duraciÃ³n estimada]

CONTINUITY NOTES (for next scene):
[Elementos visuales, posiciÃ³n de personajes, objetos, clima que deben continuar]
```
"""

def generate_scene_prompt(
    paragraph: str,
    scene_number: int,
    total_scenes: int,
    characters_description: str,
    previous_continuity: Optional[str],
    next_paragraph: Optional[str],
) -> str:
    """
    Genera el prompt de una escena individual usando GPT-4o.
    """
    context_parts = []

    if previous_continuity:
        context_parts.append(f"CONTINUITY FROM PREVIOUS SCENE:\n{previous_continuity}")

    if next_paragraph:
        context_parts.append(
            f"NEXT PARAGRAPH (for visual continuity planning):\n{next_paragraph}"
        )

    user_message = f"""
{characters_description}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CURRENT PARAGRAPH (Scene {scene_number} of {total_scenes}):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{paragraph}

{chr(10).join(context_parts)}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Generate the complete scene prompt for Scene {scene_number}.
Make it detailed enough for an AI video generator.
End with CONTINUITY NOTES for the next scene.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    response = client.chat.completions.create(
        model=MODEL_SCENE,
        messages=[
            {"role": "system", "content": SCENE_SYSTEM_PROMPT},
            {"role": "user", "content": user_message},
        ],
        temperature=0.7,
        max_tokens=1500,
    )
    return response.choices[0].message.content.strip()


def extract_continuity_notes(scene_prompt: str) -> str:
    """Extrae las CONTINUITY NOTES de un prompt de escena generado."""
    match = re.search(
        r"CONTINUITY NOTES.*?:(.*?)(?=\n[A-Z]{2,}|\Z)",
        scene_prompt,
        re.DOTALL | re.IGNORECASE,
    )
    return match.group(1).strip() if match else ""


# â”€â”€â”€ Agente Editor / Validador de coherencia â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

EDITOR_SYSTEM_PROMPT = """Eres un editor experto en narrativa visual, especializado en animaciÃ³n CGI y storyboarding.
Tu trabajo es revisar una secuencia de prompts de escenas para un video animado y evaluar:

1. COHERENCIA VISUAL: Â¿Los personajes mantienen sus caracterÃ­sticas fÃ­sicas consistentes?
2. COHERENCIA NARRATIVA: Â¿La historia fluye lÃ³gicamente de escena en escena?
3. CONTINUIDAD DE AMBIENTE: Â¿El ambiente, luz y objetos se mantienen consistentes entre escenas?
4. CONTINUIDAD DE ACCIONES: Â¿Las acciones conectan fluidamente entre escenas?
5. CLARIDAD PARA IA VIDEO: Â¿Cada prompt es lo suficientemente claro y detallado para un generador de video IA?

RESPONDE EN ESTE FORMATO JSON EXACTO (sin markdown, sin bloques de cÃ³digo):
{
  "overall_score": <nÃºmero 0-100>,
  "scene_scores": {
    "1": <nÃºmero 0-100>,
    "2": <nÃºmero 0-100>,
    ...
  },
  "issues": [
    {
      "scene": <nÃºmero>,
      "type": "visual|narrative|continuity|clarity",
      "description": "<descripciÃ³n del problema>",
      "severity": "low|medium|high"
    }
  ],
  "corrections_needed": [
    {
      "scene": <nÃºmero>,
      "original_section": "<texto exacto a reemplazar>",
      "corrected_section": "<texto corregido>",
      "reason": "<razÃ³n del cambio>"
    }
  ],
  "summary": "<resumen ejecutivo de mÃ¡ximo 3 oraciones>",
  "passed": <true si overall_score >= umbral, false en caso contrario>
}
"""

def validate_and_correct(
    scenes: dict[int, str],
    characters_description: str,
    story_paragraphs: list[str],
    threshold: int,
) -> dict:
    """
    El agente editor lee todos los prompts y devuelve un anÃ¡lisis JSON
    con puntuaciÃ³n de coherencia y correcciones necesarias.
    """
    scenes_text = "\n\n" + "=" * 60 + "\n\n"
    scenes_text = scenes_text.join(
        [f"SCENE {n}:\n{text}" for n, text in sorted(scenes.items())]
    )

    user_message = f"""
{characters_description}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ORIGINAL STORY (for reference):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chr(10).join([f'Paragraph {i+1}: {p}' for i, p in enumerate(story_paragraphs)])}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GENERATED SCENE PROMPTS TO EVALUATE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{scenes_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COHERENCE THRESHOLD: {threshold}%
Evaluate all scenes and provide corrections if overall_score < {threshold}.
Respond ONLY with the JSON format specified. No markdown, no code blocks.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    response = client.chat.completions.create(
        model=MODEL_EDITOR,
        messages=[
            {"role": "system", "content": EDITOR_SYSTEM_PROMPT},
            {"role": "user", "content": user_message},
        ],
        temperature=0.3,
        max_tokens=3000,
    )

    raw = response.choices[0].message.content.strip()
    # Limpiar posibles bloques de cÃ³digo markdown
    raw = re.sub(r"```(?:json)?", "", raw).strip()

    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        print("âš ï¸  El editor devolviÃ³ JSON invÃ¡lido. Intentando extracciÃ³n parcial...")
        # Intento de extracciÃ³n bÃ¡sica
        score_match = re.search(r'"overall_score"\s*:\s*(\d+)', raw)
        score = int(score_match.group(1)) if score_match else 50
        return {
            "overall_score": score,
            "scene_scores": {},
            "issues": [],
            "corrections_needed": [],
            "summary": raw[:300],
            "passed": score >= threshold,
        }


def apply_corrections(scenes: dict[int, str], corrections: list[dict]) -> dict[int, str]:
    """
    Aplica las correcciones sugeridas por el agente editor a las escenas.
    """
    corrected = {k: v for k, v in scenes.items()}
    applied = 0

    for fix in corrections:
        scene_num = fix.get("scene")
        original  = fix.get("original_section", "")
        corrected_text = fix.get("corrected_section", "")

        if scene_num and original and corrected_text and scene_num in corrected:
            if original in corrected[scene_num]:
                corrected[scene_num] = corrected[scene_num].replace(
                    original, corrected_text, 1
                )
                applied += 1
                print(f"   âœï¸  CorrecciÃ³n aplicada en escena {scene_num}: {fix.get('reason','')[:80]}")

    print(f"   â†’ {applied}/{len(corrections)} correcciones aplicadas.")
    return corrected


# â”€â”€â”€ GestiÃ³n de archivos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def save_scene(scene_prompt: str, scene_number: int, output_dir: Path) -> Path:
    path = output_dir / f"escena{scene_number}.md"
    path.write_text(scene_prompt, encoding="utf-8")
    return path


def load_scene(scene_number: int, output_dir: Path) -> Optional[str]:
    path = output_dir / f"escena{scene_number}.md"
    return path.read_text(encoding="utf-8") if path.exists() else None


def save_report(report: dict, iteration: int, output_dir: Path) -> Path:
    path = output_dir / f"coherence_report_v{iteration}.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    return path


def save_summary(scenes: dict, final_report: dict, output_dir: Path):
    """Genera un resumen final legible en Markdown."""
    path = output_dir / "RESUMEN_FINAL.md"
    score = final_report.get("overall_score", 0)
    passed = final_report.get("passed", False)

    lines = [
        "# ğŸ¬ RESUMEN FINAL â€” GENERADOR DE ESCENAS",
        "",
        f"## PuntuaciÃ³n de Coherencia: **{score}%** {'âœ… APROBADO' if passed else 'âŒ REQUIERE REVISIÃ“N MANUAL'}",
        "",
        f"### Resumen del Editor:",
        final_report.get("summary", "N/A"),
        "",
        "---",
        "",
        "## Puntuaciones por Escena:",
        "",
    ]

    scene_scores = final_report.get("scene_scores", {})
    for n in sorted(scenes.keys()):
        sc = scene_scores.get(str(n), scene_scores.get(n, "N/A"))
        emoji = "âœ…" if isinstance(sc, int) and sc >= 80 else "âš ï¸"
        lines.append(f"- **Escena {n}**: {sc}% {emoji}")

    issues = final_report.get("issues", [])
    if issues:
        lines += ["", "---", "", "## Problemas Detectados:", ""]
        for issue in issues:
            severity_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                issue.get("severity", "low"), "âšª"
            )
            lines.append(
                f"- {severity_emoji} **Escena {issue.get('scene')}** [{issue.get('type','?')}]: {issue.get('description','')}"
            )

    lines += [
        "",
        "---",
        "",
        "## Archivos Generados:",
        "",
    ]
    for n in sorted(scenes.keys()):
        lines.append(f"- `escena{n}.md` â€” Prompt para generador de video IA")

    lines += [
        "",
        "---",
        "_Generado automÃ¡ticamente por scene_generator.py_",
    ]

    path.write_text("\n".join(lines), encoding="utf-8")
    return path


# â”€â”€â”€ Pipeline principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_pipeline(
    story_path: str,
    characters_path: str,
    output_dir: str = ".",
    threshold: int = COHERENCE_THRESHOLD,
    only_validate: bool = False,
):
    output = Path(output_dir)
    output.mkdir(parents=True, exist_ok=True)

    print("\n" + "â•" * 60)
    print("   ğŸ¬  GENERADOR DE ESCENAS ANIMADAS â€” INICIANDO")
    print("â•" * 60 + "\n")

    # 1. Cargar datos
    print("ğŸ“‚ Cargando personajes...")
    characters_desc = load_characters(characters_path)

    print("ğŸ“– Cargando historia...")
    paragraphs = load_story(story_path)
    total = len(paragraphs)

    # 2. Generar o cargar escenas
    scenes: dict[int, str] = {}

    if only_validate:
        print("\nğŸ” Modo solo-validaciÃ³n: cargando escenas existentes...")
        for i in range(1, total + 1):
            content = load_scene(i, output)
            if content:
                scenes[i] = content
                print(f"   âœ… escena{i}.md cargada")
            else:
                print(f"   âŒ escena{i}.md no encontrada â€” salteando")
    else:
        print(f"\nğŸ–Šï¸  Generando {total} prompts de escenas...\n")
        continuity = None

        for i, paragraph in enumerate(paragraphs, start=1):
            print(f"  ğŸ¨ Generando escena {i}/{total}...")

            next_para = paragraphs[i] if i < total else None

            prompt = generate_scene_prompt(
                paragraph=paragraph,
                scene_number=i,
                total_scenes=total,
                characters_description=characters_desc,
                previous_continuity=continuity,
                next_paragraph=next_para,
            )

            scenes[i] = prompt
            path = save_scene(prompt, i, output)
            continuity = extract_continuity_notes(prompt)

            print(f"     âœ… escena{i}.md guardada â†’ {path}")
            time.sleep(0.5)  # PequeÃ±a pausa entre llamadas

    if not scenes:
        print("âŒ No hay escenas para validar. Abortando.")
        return

    # 3. Bucle de validaciÃ³n y correcciÃ³n
    print(f"\n{'â•'*60}")
    print(f"   ğŸ”¬  AGENTE EDITOR â€” VALIDANDO COHERENCIA (umbral: {threshold}%)")
    print(f"{'â•'*60}\n")

    final_report = None
    for iteration in range(1, MAX_FIX_ITERATIONS + 1):
        print(f"  IteraciÃ³n {iteration}/{MAX_FIX_ITERATIONS}...")

        report = validate_and_correct(scenes, characters_desc, paragraphs, threshold)
        final_report = report

        score   = report.get("overall_score", 0)
        passed  = report.get("passed", False)
        issues  = report.get("issues", [])
        fixes   = report.get("corrections_needed", [])

        report_path = save_report(report, iteration, output)
        print(f"   ğŸ“Š PuntuaciÃ³n: {score}% | Problemas: {len(issues)} | Correcciones: {len(fixes)}")
        print(f"   ğŸ“„ Reporte guardado: {report_path}")

        if passed:
            print(f"\n   âœ… COHERENCIA APROBADA ({score}% â‰¥ {threshold}%)")
            break

        if fixes and iteration < MAX_FIX_ITERATIONS:
            print(f"\n   âš™ï¸  Aplicando correcciones automÃ¡ticas...")
            scenes = apply_corrections(scenes, fixes)
            # Re-guardar escenas corregidas
            for n, text in scenes.items():
                save_scene(text, n, output)
            print()
        elif iteration == MAX_FIX_ITERATIONS:
            print(
                f"\n   âš ï¸  Se alcanzÃ³ el mÃ¡ximo de iteraciones. "
                f"PuntuaciÃ³n final: {score}%. RevisiÃ³n manual recomendada."
            )

    # 4. Resumen final
    summary_path = save_summary(scenes, final_report or {}, output)

    print(f"\n{'â•'*60}")
    print(f"   ğŸ  PROCESO COMPLETADO")
    print(f"{'â•'*60}")
    print(f"\n   ğŸ“ Archivos generados en: {output.resolve()}")
    for n in sorted(scenes.keys()):
        print(f"      â€¢ escena{n}.md")
    print(f"      â€¢ RESUMEN_FINAL.md")
    print(f"      â€¢ coherence_report_v*.json\n")


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="Generador de prompts de escenas animadas para IA de video"
    )
    parser.add_argument(
        "--story",
        default="historia.md",
        help="Ruta al archivo historia.md (default: historia.md)",
    )
    parser.add_argument(
        "--characters",
        default="characters.json",
        help="Ruta al JSON de personajes (default: characters.json)",
    )
    parser.add_argument(
        "--output",
        default=".",
        help="Directorio de salida (default: directorio actual)",
    )
    parser.add_argument(
        "--threshold",
        type=int,
        default=COHERENCE_THRESHOLD,
        help=f"Porcentaje mÃ­nimo de coherencia (default: {COHERENCE_THRESHOLD})",
    )
    parser.add_argument(
        "--only-validate",
        action="store_true",
        help="Solo valida escenas existentes sin regenerarlas",
    )

    args = parser.parse_args()

    run_pipeline(
        story_path=args.story,
        characters_path=args.characters,
        output_dir=args.output,
        threshold=args.threshold,
        only_validate=args.only_validate,
    )


if __name__ == "__main__":
    main()
